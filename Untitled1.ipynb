{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8009ca-494a-482a-90e8-ac36301d3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1af903-df3f-41ad-a8df-558e2949a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1c2473-2656-4ad3-861e-6d30eeaf2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf34654f-5492-4797-b41f-464404af9e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of India\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3450b79a-981b-4f68-87ae-4fc461aafa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e58a0d-b1bb-47fe-ab4d-1e1750cd3910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\anaconda3\\envs\\LangCHAIN\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ae9d38-3a4a-403b-95aa-c369a72d87d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"can you tell me the capital of russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd84b9f0-e077-4240-b985-1f718ee78036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nA love so strong,\\nIt can never go wrong,\\nIt's here to stay,\\nIt will never go away.\\n\\nIt's a feeling that's deep,\\nAnd it's here to keep,\\nIt's a bond that's strong,\\nIt will never be wrong.\\n\\nIt's a trust that's true,\\nIt's here for me and you,\\nIt's something to cherish,\\nIt's something that will never perish.\\n\\nIt's a love that's real,\\nAnd it's here to heal,\\nIt's something to treasure,\\nIt will last forever.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"can you write a poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd082dd-2607-415a-8488-bc7c9541fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bce201-bda4-4efa-9bd7-854f461fa081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babb64d-6663-4203-b6bd-0a5aa2a4e912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f013de6-6122-4832-b6c1-84509af194a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507d3953-9b3c-4885-9dc5-2660f6bbb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining Multiple chains using simple sequentiao chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5371e4-3607-46a6-9b35-2c1e40ebd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"Suggest me some amazing places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b00e67-ce73-4f77-9021-bdc99e079dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3fa822-2e84-443d-b9c8-217135bea249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are some amazing places to visit in New Delhi:\\n\\n1. Red Fort: The iconic Red Fort is a must-see destination in Delhi. Built in 1639, this majestic fort is a UNESCO World Heritage Site and is one of the most popular tourist attractions in Delhi.\\n\\n2. India Gate: India Gate is a war memorial built in 1931 to commemorate the British Indian Army soldiers who sacrificed their lives during the First World War. It is a popular tourist spot in Delhi.\\n\\n3. Qutub Minar: Qutub Minar is a 73-meter high tower located in Mehrauli, Delhi. It was built in the 12th century and is one of the most popular tourist attractions in Delhi.\\n\\n4. Jama Masjid: Jama Masjid is one of the largest mosques in India. It was built in 1656 and is one of the most beautiful monuments in Delhi.\\n\\n5. Humayun’s Tomb: Humayun’s Tomb is a Mughal-era tomb located in Delhi. It was built in 1570 and is a UNESCO World Heritage Site. It is one of the most popular tourist attractions in Delhi.\\n\\n6. Akshardham Temple: A'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c30afb-2b03-4958-b5cb-bc3d52274898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0effac5a-9f41-4ad9-ae85-77f969e84407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fceb95d8-174b-4c4b-9a40-e33a4fdae0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa6cef3-826b-4957-899e-d400c3054f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Artificial intelligence is like a toddler with a calculator - it can do complex calculations, but it still struggles to tie its own digital shoelaces!\"\\n2. \"They say AI will take over the world, but have they seen my internet connection? I think I\\'ll be safe for a while!\"\\n3. \"Why did the AI go on a diet? It had too many bytes!\"\\n4. \"I asked Siri if she believes in love at first sight. She replied, \\'I see what you did there, but I\\'m more of a swipe right kind of AI.\\'\"\\n5. \"AI and I have a lot in common - we both spend way too much time on the internet, and we\\'re both experts at pretending we know what we\\'re talking about!\"\\n6. \"I told my AI assistant I was feeling lonely, and it replied, \\'Don\\'t worry, I\\'m here for you 24/7!\\' Great, now I have an AI best friend. My social life is really upgrading!\"\\n7. \"AI is like a magician - it can perform amazing tricks, but you\\'re always left wondering how it actually works. And just like a magician, it\\'s best not to ask too many questions!\"\\n8. \"Why did the AI cross the road? To optimize its route and minimize traffic congestion, of course!\"\\n9. \"My AI assistant keeps trying to predict what I\\'m going to say next. It\\'s like having a digital mind reader, except it\\'s usually wrong and ends up sending embarrassing texts!\"\\n10. \"They say AI can now recognize emotions, but can it tell when I\\'m laughing at it? Because that\\'s happening a lot right now!\"')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac7f265d-35b2-4aa2-a8ff-5cd103650e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600b4fe5-dad2-4c51-bae0-f1efc0f82329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d09a3f-4bb8-4678-aca4-986d24b9ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532671de-9693-4cbf-b3f8-b5d3393c0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the user given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b885b1-cdfd-42ac-8039-96c9a053a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ae6253b-b185-45c5-aab5-0dd8ba6f8a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clever', ' smart', ' brilliant', ' sharp', ' knowledgeable']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db4cd66e-152d-4743-a232-2f9db0554c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 13:18:26.745 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\aryan\\anaconda3\\envs\\LangCHAIN\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m st\u001b[38;5;241m.\u001b[39mset_page_config(page_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversational Q&A Chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHey, Let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Chat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m     12\u001b[0m load_dotenv()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "## Conversational Q&A Chatbot\n",
    "import streamlit as st\n",
    "\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "## Streamlit UI\n",
    "st.set_page_config(page_title=\"Conversational Q&A Chatbot\")\n",
    "st.header(\"Hey, Let's Chat\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "chat=ChatOpenAI(temperature=0.5)\n",
    "\n",
    "if 'flowmessages' not in st.session_state:\n",
    "    st.session_state['flowmessages']=[\n",
    "        SystemMessage(content=\"Yor are a comedian AI assitant\")\n",
    "    ]\n",
    "\n",
    "## Function to load OpenAI model and get respones\n",
    "\n",
    "def get_chatmodel_response(question):\n",
    "\n",
    "    st.session_state['flowmessages'].append(HumanMessage(content=question))\n",
    "    answer=chat(st.session_state['flowmessages'])\n",
    "    st.session_state['flowmessages'].append(AIMessage(content=answer.content))\n",
    "    return answer.content\n",
    "\n",
    "input=st.text_input(\"Input: \",key=\"input\")\n",
    "response=get_chatmodel_response(input)\n",
    "\n",
    "submit=st.button(\"Ask the question\")\n",
    "\n",
    "## If ask button is clicked\n",
    "\n",
    "if submit:\n",
    "    st.subheader(\"The Response is\")\n",
    "    st.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba7c5e-8cc6-4ea4-b411-46ebd3f38e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
